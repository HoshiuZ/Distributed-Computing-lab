# å®éªŒç›®çš„

1. å­¦ä¹ åŸºäºMPIåˆ†å¸ƒå¼å¹¶è¡Œè®¡ç®—ç¨‹åºè®¾è®¡æ–¹æ³•ã€‚ 
2. å­¦ä¹ åŸºäºMapReduceæ¡†æ¶çš„åˆ†å¸ƒå¼å¹¶è¡Œè®¡ç®—ç¨‹åºè®¾è®¡æ–¹æ³•ã€‚ 
3. å­¦ä¹ åŸºäºSparkæ¡†æ¶çš„åˆ†å¸ƒå¼å¹¶è¡Œè®¡ç®—ç¨‹åºè®¾è®¡æ–¹æ³•ã€‚

# å®éªŒé¢˜ç›®

## é¢˜ç›® 1

ç¼–å†™åŸºäº MPI çš„å¹¶è¡Œè®¡ç®—ç¨‹åºï¼Œå®ç°å¯¹è¿ç»­å‡½æ•° $f(x)=\sin(x^2+ğ‘¥)(x\in R)$ åœ¨åŒº é—´ $[a, b]$ ä¸Šçš„å®šç§¯åˆ†æ±‚è§£ã€‚è¦æ±‚ä½¿ç”¨â€œæ¢¯å½¢æ³•ï¼ˆTrapezoidal Ruleï¼‰â€è¿›è¡Œè¿‘ä¼¼è®¡ç®—ã€‚

## é¢˜ç›® 2

è¾“å…¥æ–‡ä»¶ä¸ºå­¦ç”Ÿæˆç»©ä¿¡æ¯ï¼ŒåŒ…å«äº†å¿…ä¿®è¯¾ä¸é€‰ä¿®è¯¾æˆç»©ï¼Œæ ¼å¼å¦‚ä¸‹ï¼š 
ç­çº§1, å§“å1, ç§‘ç›®1, å¿…ä¿®, æˆç»©1  `<br>`ï¼ˆæ³¨ï¼š`<br>` ä¸ºæ¢è¡Œç¬¦ï¼‰ 
ç­çº§2, å§“å2, ç§‘ç›®1, å¿…ä¿®, æˆç»©2  `<br>`
ç­çº§1, å§“å1, ç§‘ç›®2, é€‰ä¿®, æˆç»©3  `<br>`
â€¦â€¦â€¦., â€¦â€¦â€¦, â€¦â€¦â€¦, â€¦â€¦â€¦  `<br>`
ç¼–å†™ Hadoop å¹³å°ä¸Šçš„ MapReduce ç¨‹åºï¼Œåˆ†åˆ«å®ç°å¦‚ä¸‹åŠŸèƒ½ï¼š 
1. è®¡ç®—æ¯ä¸ªå­¦ç”Ÿå¿…ä¿®è¯¾çš„å¹³å‡æˆç»©ã€‚ 
2. ç»Ÿè®¡æ¯ä¸ªç­çº§ä¸­æ‰€æœ‰è¯¾ç¨‹ï¼ˆå¿…ä¿®+é€‰ä¿®ï¼‰å¹³å‡æˆç»©æ’åå‰äº”çš„å­¦ç”Ÿå§“åå’Œæˆç»©

## é¢˜ç›® 3

è¾“å…¥æ–‡ä»¶çš„æ¯ä¸€è¡Œä¸ºå…·æœ‰çˆ¶å­/çˆ¶å¥³/æ¯å­/æ¯å¥³/å…³ç³»çš„ä¸€å¯¹äººåï¼Œä¾‹å¦‚ï¼š 
Tim, Andy `<br>` 
Harry, Alice  `<br`>
Mark, Louis  `<br>`
Andy, Joseph  `<br>`
â€¦â€¦â€¦.., â€¦â€¦â€¦â€¦  `<br>`
å‡å®šä¸ä¼šå‡ºç°é‡åç°è±¡ã€‚ 
ç¼–å†™ Hadoop å¹³å°ä¸Šçš„ MapReduce ç¨‹åºï¼Œæ‰¾å‡ºæ‰€æœ‰å…·æœ‰ grandchild-grandparent å…³ç³»çš„äººåå¯¹ã€‚

## é¢˜ç›® 4

è¾“å…¥æ–‡ä»¶ä¸ºå­¦ç”Ÿæˆç»©ä¿¡æ¯ï¼ŒåŒ…å«äº†å¿…ä¿®è¯¾ä¸é€‰ä¿®è¯¾æˆç»©ï¼Œæ ¼å¼å¦‚ä¸‹ï¼š 
ç­çº§1, å§“å1, ç§‘ç›®1, å¿…ä¿®, æˆç»©1  `<br>`ï¼ˆæ³¨ï¼š  `<br>` ä¸ºæ¢è¡Œç¬¦ï¼‰ 
ç­çº§2, å§“å2, ç§‘ç›®1, å¿…ä¿®, æˆç»©2 `<br>` 
ç­çº§1, å§“å1, ç§‘ç›®2, é€‰ä¿®, æˆç»©3 `<br>` 
â€¦â€¦â€¦., â€¦â€¦â€¦, â€¦â€¦â€¦, â€¦â€¦â€¦  `<br>`
ç¼–å†™Sparkç¨‹åºï¼Œå®ç°å¦‚ä¸‹åŠŸèƒ½ï¼š æŒ‰ç­çº§ç»Ÿè®¡å¿…ä¿®è¯¾å¹³å‡æˆç»©åœ¨ï¼š90~100ã€80~89ã€70~79ã€60~69 å’Œ 60 åˆ†ä»¥ä¸‹è¿™ 5 ä¸ªåˆ†æ•°æ®µçš„å­¦ç”Ÿäººæ•°ã€‚
# å‡†å¤‡å·¥ä½œ

## å®‰è£… Microsoft MPI

é¦–å…ˆéœ€è¦å®‰è£… Microsoft MPIã€‚

å‚è€ƒäº† [windowså®‰è£…MPIåŠpythonå®‰è£…mpi4py_ä¸‹è½½mpi4pyä»£ç åœ¨vmware-CSDNåšå®¢](https://blog.csdn.net/wavehaha/article/details/123314904)ã€‚

ç›´æ¥ç…§ç€ä¸‹è½½å®‰è£…é…ç½®ç¯å¢ƒå˜é‡å³å¯ã€‚

## å®‰è£… Docker

### å®‰è£… WSL 2

Docker Desktop for Windows éœ€è¦ WSL 2 æ”¯æŒï¼Œæ‰€ä»¥éœ€è¦å…ˆå®‰è£… WSL 2ã€‚

å‚è€ƒäº† [# Windows10å®‰è£…WSLçš„Ubuntu20.04ç³»ç»ŸåŠè¸©å‘è®°å½•](https://zhuanlan.zhihu.com/p/548065971)

### å®‰è£… Docker

å‚è€ƒäº† [åœ¨å›½å†… Windows å¹³å°ä¸Šå®‰è£… Docker çš„è¯¦ç»†æ•™ç¨‹_docker windows intel-CSDNåšå®¢](https://blog.csdn.net/HYP_Coder/article/details/141753300)

## éƒ¨ç½² Hadoop å’Œ Spark å®éªŒç¯å¢ƒ

`git clone` ä¸€ä¸‹ [hadoop-sandbox/hadoop-sandbox: A fully-functional Hadoop Yarn cluster as docker-compose deployment.](https://github.com/hadoop-sandbox/hadoop-sandbox)

ç„¶ååˆ‡æ¢åˆ°è§£å‹åçš„ç›®å½•ä¸‹ï¼Œä½¿ç”¨ `powershell` æ‰§è¡Œ `docker-compose up -d`ï¼Œä¼šæ ¹æ®è¯¥ç›®å½•ä¸‹ `.yml` æ–‡ä»¶æ¥ä¸‹è½½é•œåƒå¹¶å¯åŠ¨å®¹å™¨ã€‚

æ¥ç€æ‰§è¡Œ `docker-compose down` æ¥å…³é—­å¯åŠ¨çš„å®¹å™¨ã€‚

ä¸‹è½½è€å¸ˆæä¾›çš„ `spark-install.zip` å‹ç¼©åŒ…ï¼Œå¹¶è§£å‹ã€‚ç„¶åç”¨ `powershell` åˆ‡æ¢åˆ°è§£å‹åçš„ç›®å½•ï¼Œå¹¶æ‰§è¡Œ `docker build -t packet23/hadoop-client:latest .` ï¼Œæ­¤å‘½ä»¤å°†æ ¹æ® `Dockerfile` çš„æŒ‡ç¤ºåœ¨åä¸º `hadoop-client` çš„ Docker é•œåƒä¸­ä¸‹è½½å¹¶å®‰è£… Python3.8ï¼ŒSpark-3.2.1 å’Œ apache-maven-3.8.5ã€‚

ä¸Šè¿°æ“ä½œç»“æŸåå°±æˆåŠŸç”Ÿæˆäº†å®éªŒæ‰€éœ€çš„å…¨éƒ¨ Docker é•œåƒã€‚

## ä¸º clientnode å®‰è£… mrjob åº“

ç”±äºæˆ‘ä½¿ç”¨çš„è¯­è¨€ä¸º `Python`ï¼Œæ‰€ä»¥éœ€è¦ä¸ºå®¹å™¨å®‰è£… `mrjob` åº“ã€‚

ç”±äºå®¹å™¨å†…æ²¡æœ‰ `pip`ï¼Œæ‰€ä»¥å…ˆè¦å¯¹å…¶å®‰è£… `pip`ã€‚

å…ˆ `docker ps` æŸ¥çœ‹ `clientnode` å®¹å™¨ IDï¼Œç„¶å `docker exec -it --user root clientnode bash` ï¼ˆå…¶ä¸­ `clientnode` æ¢æˆå®¹å™¨ IDï¼‰ï¼Œè¿›å…¥åå†æ‰§è¡Œ

```bash
apt update
apt install -y python3-pip
pip3 install mrjob
```

å¦‚æ­¤ï¼Œä¾¿å®‰è£…å¥½äº† `mrjob` åº“ã€‚

## ä¸º nodemanager å®‰è£… python3

å†æµ‹è¯•è€å¸ˆç»™çš„ä»£ç æ—¶ï¼Œå‘ç° `nodemanager` æ²¡æœ‰å®‰è£… `python3` ï¼Œæ— æ³•è¿è¡Œã€‚

æ‰€ä»¥éœ€è¦å¯¹å…¶å®‰è£… `python3`ã€‚

å…ˆ `docker ps` æŸ¥çœ‹ `nodemaanager` å®¹å™¨ IDï¼Œç„¶å `docker exec -it --user root nodemanager bash` ï¼ˆå…¶ä¸­ `nodemanager` æ¢æˆå®¹å™¨ IDï¼‰ï¼Œè¿›å…¥åå†æ‰§è¡Œ

```bash
apt-get update
apt-get install -y python3 python3-pip
```

å¦‚æ­¤ï¼Œä¾¿æˆåŠŸä¸º `nodemanager` å®‰è£…äº† `python3` ã€‚
# å®éªŒæ€è·¯

## é¢˜ç›® 1

æ¢¯å½¢æ³•è®¡ç®—å®šç§¯åˆ†è¿‘ä¼¼å€¼ã€‚

è€ƒè™‘å°†å®šç§¯åˆ†åŒºé—´åˆ†æˆ n ä¸ªå­åŒºé—´ï¼Œç„¶åå†å‡åˆ†ç»™è¿›ç¨‹ï¼ˆå¼€çš„è¿›ç¨‹æ•°æ˜¯ n çš„å› æ•°ï¼Œå‡è®¾ä¸º size ï¼‰ï¼Œæ¯ä¸ªè¿›ç¨‹è®¡ç®— n // size ä¸ª å­åŒºé—´ç”¨æ¢¯å½¢æ³•è®¡ç®—å‡ºçš„å€¼çš„å’Œï¼Œç„¶åå†ç”¨ Reduce å‡½æ•°æ¥æŠŠå„ä¸ªè¿›ç¨‹çš„ç»“æœç”¨ MPI.SUM ç´¯åŠ èµ·æ¥å³å¯ã€‚

## é¢˜ç›® 2

å¯¹äºç¬¬ä¸€ä¸ªè¦æ±‚ï¼Œè®¡ç®—æ¯ä¸ªå­¦ç”Ÿå¿…ä¿®è¯¾çš„å¹³å‡æˆç»©ï¼Œåœ¨ map é˜¶æ®µåªéœ€å°†æ¯ä¸€è¡Œä¿¡æ¯è½¬æ¢æˆé”®å€¼å¯¹ `{(ç­çº§, å§“å), (å¿…ä¿®è¯¾åˆ†æ•°, 1)}`ï¼Œé”®åŠ å…¥ç­çº§æ˜¯ä¸ºäº†é¿å…é‡åé—®é¢˜ã€‚ç„¶ååœ¨ reduce é˜¶æ®µå¯¹åŒä¸€ä¸ªäººçš„æˆç»©è¿›è¡Œèšåˆï¼Œè®¡ç®—æ¯ä¸ªäººçš„å¿…ä¿®è¯¾å¹³å‡æˆç»©å³å¯ã€‚

åœ¨åšç¬¬ä¸€ä¸ªè¦æ±‚çš„æ—¶å€™é‡åˆ°äº†ä¸€ä¸ªé—®é¢˜ï¼ŒèŠ±äº†å¾ˆé•¿æ—¶é—´æ‰è§£å†³ï¼Œé‚£å°±æ˜¯è¾“å‡ºçš„æ–‡ä»¶çš„ä¸­æ–‡æ€»æ˜¯ä¼šå˜æˆ `unicode` ç¼–ç ã€‚é—®äº†å¾ˆä¹…å¤§æ¨¡å‹ï¼Œæä¾›çš„æ–¹æ³•éƒ½æ— æ³•è§£å†³ã€‚æœ€åæ— æœå» google äº†ä¸€ä¸‹ï¼Œåœ¨ `mrjob` çš„ `github` ä»“åº“æ‰¾åˆ°äº†ä¸€ä¸ª [issue](https://github.com/Yelp/mrjob/issues/1442)ï¼Œä¹Ÿæ˜¯è·Ÿæˆ‘ä¸€æ ·çš„é—®é¢˜ï¼Œå‚è€ƒäº†ä¸€ä¸‹æˆåŠŸè§£å†³äº†ã€‚çœ‹æ¥è¿˜æ˜¯ä¸èƒ½å¤ªä¾èµ–å¤§æ¨¡å‹ï¼ˆå½“ç„¶ä¹Ÿæœ‰å¯èƒ½æ˜¯æˆ‘æé—®çš„å§¿åŠ¿ä¸å¤ªå¯¹ï¼‰ã€‚

å¯¹äºç¬¬äºŒä¸ªè¦æ±‚ï¼Œåœ¨ map é˜¶æ®µæŠŠæ¯ä¸€è¡Œä¿¡æ¯è½¬æ¢ä¸ºé”®å€¼å¯¹ `{ç­çº§, (å§“å, åˆ†æ•°, 1)}`ã€‚åœ¨ reduce é˜¶æ®µå¯¹åŒä¸€ä¸ªç­çº§çš„å­¦ç”Ÿæˆç»©ï¼Œå¼€ä¸€ä¸ªå­—å…¸ç»Ÿè®¡å…¶æ€»åˆ†ä¸ç§‘ç›®æ•°ï¼Œç”¨äºè®¡ç®—å¹³å‡æˆç»©ï¼Œæ¥ç€æ ¹æ®å¹³å‡æˆç»©è¿›è¡Œä»é«˜åˆ°ä½æ’åºï¼Œå–å‰äº”å³å¯ã€‚

## é¢˜ç›® 3

æ ¹æ®ç»™å‡ºçš„äº²å­å…³ç³»å¯ä»¥ç”»å‡ºä¸€ä¸ªå›¾ï¼Œè¦æ‰¾ grandchild-grandparent å…³ç³»çš„è¯ï¼Œåªéœ€æ‰¾ä¸€ä¸ªä¸­ä»‹ç‚¹ï¼Œå…¶æ‰€æœ‰å­ä»£ä¸çˆ¶ä»£ç›¸äº’ä¹‹é—´æ„æˆ grandchild-grandparent å…³ç³»ã€‚

æ‰€ä»¥ï¼Œåœ¨ map é˜¶æ®µï¼Œå°†æ¯è¡Œçš„ä¿¡æ¯ `A,B`ï¼Œè¾“å‡ºä¸¤ä¸ªé”®å€¼å¯¹ `{A, ("child", B)}, {B, ("parent", A)}`ï¼Œåˆ†åˆ«ä»£è¡¨ A çš„å­©å­æ˜¯ Bï¼ŒB çš„çˆ¶æ¯æ˜¯ Aã€‚

åœ¨ reduce é˜¶æ®µï¼Œå¯¹åŒä¸€ä¸ªäººçš„ä¿¡æ¯è¿›è¡Œèšåˆï¼Œå¼€ä¸¤ä¸ªåˆ—è¡¨åˆ†åˆ«å­˜å‚¨è¿™ä¸ªäººçš„å­©å­ä¸çˆ¶æ¯ï¼Œæ¥ç€æŠŠè¿™ä¸¤ä¸ªåˆ—è¡¨ç›¸äº’ä¹‹é—´è¾“å‡º grandchild-grandparent å…³ç³»å³å¯ã€‚

## é¢˜ç›® 4

æ˜¾ç„¶ï¼Œè¿™ä¸ªé¢˜ç›®éœ€è¦ç”¨åˆ°é¢˜ç›® 2 çš„è¦æ±‚ 1 ç”Ÿæˆçš„ç»“æœã€‚

è¿™ä¸ªç»“æœçš„æ ¼å¼ä¸º `ç­çº§ å§“å å¿…ä¿®è¯¾å¹³å‡æˆç»©`ã€‚

æ‰€ä»¥è¯»å…¥ä¹‹åï¼Œå…ˆå¯¹å…¶è¿›è¡Œä¸¤æ¬¡ mapï¼Œç¬¬ä¸€æ¬¡å°†ä¿¡æ¯æŒ‰ç…§ç©ºæ ¼åˆ†å‰²æˆä¸€ä¸ªåˆ—è¡¨ï¼Œç¬¬äºŒæ¬¡å°†åˆ—è¡¨çš„ç¬¬ä¸€ä¸ªå­—æ®µå’Œç¬¬ä¸‰ä¸ªå­—æ®µï¼ˆç­çº§å’Œåˆ†æ•°ï¼Œå› ä¸ºä¸éœ€è¦å…³æ³¨å§“åï¼‰å½¢æˆé”®å€¼å¯¹ï¼Œå½¢æˆäº†ä¸€ä¸ªé”®å€¼å¯¹ rddã€‚

å¾—åˆ°è¿™ä¸ªé”®å€¼å¯¹ rdd åï¼Œå¯ä»¥å†™ä¸€ä¸ªå‡½æ•°æ¥æŠŠåˆ†æ•°æ˜ å°„åˆ°å¯¹åº”çš„åŒºé—´ï¼Œç„¶åç”Ÿæˆå½¢å¦‚ `{ç­çº§, (åˆ†æ•°åŒºé—´, 1)}` çš„é”®å€¼å¯¹ï¼Œè¿™ä¸ªåªéœ€å†™å¥½è¿™ä¸ªåˆ†æ•°æ˜ å°„å‡½æ•°ä¹‹åä½¿ç”¨ `mapValues` ç®—å­å³å¯ã€‚

ç„¶åï¼Œæ˜¯å¯¹åŒä¸€ä¸ªç­çº§çš„åŒä¸€ä¸ªåˆ†æ•°åŒºé—´è¿›è¡Œè®¡æ•°ç»Ÿè®¡ï¼Œæ‰€ä»¥å¯ä»¥æŠŠåŸé”®å€¼å¯¹ `{ç­çº§, (åˆ†æ•°åŒºé—´, 1)}` å˜æˆä¸€ä¸ªæ–°çš„é”®å€¼å¯¹ `{(ç­çº§, åˆ†æ•°åŒºé—´), 1)}` ï¼Œè¿™æ ·æ–¹ä¾¿ç»Ÿè®¡ç»“æœã€‚è¿™ä¸ªä¹Ÿæ˜¯ç”¨ `map` ç®—å­å³å¯ã€‚

ç„¶åç»Ÿè®¡ç»“æœå°±å¾ˆç®€å•äº†ï¼Œç›´æ¥ç”¨ `reduceByKey` å³å¯ã€‚

ä¸ºäº†ä½¿ç»“æœæ›´æ¸…æ™°ï¼Œæˆ‘ä½¿ç”¨ `sortByKey` å‡½æ•°æŠŠç»“æœæŒ‰ç…§åŒºé—´ä»å°åˆ°å¤§çš„é¡ºåºæ¥è¾“å‡ºäº†ã€‚
# ä»£ç 

## é¢˜ç›® 1

```python
from mpi4py import MPI  
from math import sin  
  
def f(x):  
    return sin(x * x + x)  
  
comm = MPI.COMM_WORLD  
rank = comm.Get_rank()  
size = comm.Get_size()  
  
if rank == 0:  
    a = float(input("è¯·è¾“å…¥å®šç§¯åˆ†ä¸‹é™ï¼š"))  
    b = float(input("è¯·è¾“å…¥å®šç§¯åˆ†ä¸Šé™ï¼š"))  
else :  
    a = None  
    b = None  
  
a = comm.bcast(a, root=0)  
b = comm.bcast(b, root=0)  
  
n = 10000000  
chunk_size = n // size  
length = (b - a) / n  
  
partial_res = 0  
for i in range(0, chunk_size):  
    l = a + (rank * chunk_size + i) * length  
    partial_res += length * (f(l) + f(l + length)) * 0.5  
  
total_res = comm.reduce(partial_res, MPI.SUM, root=0)  
  
if rank == 0:  
    print(f"è¿‘ä¼¼å€¼ä¸ºï¼š{total_res}")
```

## é¢˜ç›® 2

### 1.

```python
# aveScore.py
from mrjob.job import MRJob  
from mrjob.protocol import RawProtocol  
  
class MRAveScore(MRJob):  
    OUTPUT_PROTOCOL = RawProtocol  
    # Mapperå‡½æ•°ï¼šæŠŠæ¯ä¸€è¡Œä¿¡æ¯åˆ†è§£å‡ºæ¥ï¼Œç„¶åä¸ºæ¯ä¸€è¡Œä¿¡æ¯ç”Ÿæˆä¸€ä¸ªé”®å€¼å¯¹{(ç­çº§, å§“å), (å¿…ä¿®è¯¾åˆ†æ•°, 1)}  
    def mapper(self, _, line):  
        cls, name, subject, subject_type, score = line.strip().split(',')  
        score = float(score)  
        if subject_type == "å¿…ä¿®":  
            yield (cls, name), (score, 1)  
  
    # Reducerå‡½æ•°ï¼šå¯¹åŒä¸€ä¸ªäººçš„æˆç»©è¿›è¡Œèšåˆï¼Œè®¡ç®—æ¯ä¸ªäººçš„å¿…ä¿®è¯¾å¹³å‡æˆç»©ã€‚  
    def reducer(self, key, values):  
        total_score = 0  
        total_num = 0  
        for score, num in values:  
            total_score += score  
            total_num += num  
        average_score = total_score / total_num if total_num else 0  
        yield f"{key[0]} {key[1]}", f"{average_score:.2f}"  
  
if __name__ == '__main__':  
    MRAveScore().run()
```

### 2.

```python
# top5.py
from mrjob.job import MRJob  
from mrjob.protocol import RawProtocol  
  
class MRTop5(MRJob):  
    OUTPUT_PROTOCOL = RawProtocol  
  
    # Mapperå‡½æ•°ï¼šæŠŠæ¯ä¸€è¡Œçš„ä¿¡æ¯åˆ†è§£å‡ºæ¥ï¼Œç”Ÿæˆé”®å€¼å¯¹ {ç­çº§, (å§“å, åˆ†æ•°, 1)}  
    def mapper(self, _, line):  
        cls, name, subject, subject_type, score = line.strip().split(',')  
        score = float(score)  
        yield cls, (name, score, 1)  
  
    # Reducerå‡½æ•°ï¼šå¯¹åŒä¸€ä¸ªç­çº§çš„å­¦ç”Ÿä¿¡æ¯è¿›è¡Œèšåˆï¼Œå¼€ä¸€ä¸ª scores å­—å…¸ç”¨æ¥ç»Ÿè®¡è¯¥ç­çº§å†…çš„å­¦ç”Ÿæ€»åˆ†ä¸ç§‘ç›®æ•°ï¼Œç”¨äºè®¡ç®—å¹³å‡æˆç»©  
    def reducer(self, key, values):  
        scores = {}  
  
        for name, score, num in values:  
            if name not in scores:  
                scores[name] = [0.0, 0]  
            scores[name][0] += score  
            scores[name][1] += num  
  
        avg_scores = [(name, score / num) for name, (score, num) in scores.items()]  
  
        top5 = sorted(avg_scores, key=lambda x: x[1], reverse=True)[:5]  
  
        for name, score in top5:  
            yield key, f"{name}\t{score:.2f}"  
  
if __name__ == '__main__':  
    MRTop5.run()
```

## é¢˜ç›® 3

```python
from mrjob.job import MRJob  
  
class MRFindGrandparents(MRJob):  
    # Mapperå‡½æ•°ï¼šè¾“å‡ºä¸¤ä¸ªé”®å€¼å¯¹ `{A, ("child", B)}, {B, ("parent", A)}`ï¼Œåˆ†åˆ«ä»£è¡¨ A çš„å­©å­æ˜¯ Bï¼ŒB çš„çˆ¶æ¯æ˜¯ Aã€‚  
    def mapper(self, _, line):  
        parent, child = line.strip().split(',')  
        yield parent, ("child", child)  
        yield child, ("parent", parent)  
  
    # Reducerå‡½æ•°ï¼šå¯¹åŒä¸€ä¸ªäººçš„ä¿¡æ¯è¿›è¡Œèšåˆï¼Œç”Ÿæˆ grandchild-grandparent å…³ç³»  
    def reducer(self, key, values):  
        parents = []  
        children = []  
        for relation, name in values:  
            if relation == "child":  
                children.append(name)  
            else:  
                parents.append(name)  
        for child in children:  
            for parent in parents:  
                yield child, parent  
  
if __name__ == '__main__':  
    MRFindGrandparents.run()
```

## é¢˜ç›® 4

```python
from pyspark import SparkContext  
  
# åˆ†æ•°æ˜ å°„åˆ°åŒºé—´å‡½æ•°  
def score_to_range(score):  
    if score < 60:  
        return "0~59"  
    elif score < 70:  
        return "60~69"  
    elif score < 80:  
        return "70~79"  
    elif score < 90:  
        return "80~89"  
    else:  
        return "90~100"  
  
def score_statistics(input_file):  
    sc = SparkContext("local", "Score Statistics")  
  
    data_rdd = sc.textFile(input_file)  
  
    class_score = data_rdd.map(lambda line: line.split()).map(lambda fields: (fields[0], float(fields[2])))  
  
    # åˆ†æ•°æ˜ å°„åˆ°åŒºé—´  
    class_score_ranges = class_score.mapValues(lambda score: (score_to_range(score), 1))  
  
    # å°†é”®å˜ä¸º {ç­çº§, åˆ†æ•°åŒºé—´}ï¼Œæ–¹ä¾¿ç»Ÿè®¡æ•°é‡  
    class_score_counts = class_score_ranges.map(lambda x: ((x[0], x[1][0]), x[1][1]))  
  
    class_score_result = class_score_counts.reduceByKey(lambda x, y: x + y)  
  
    result = class_score_result.sortByKey(ascending=True, numPartitions=1).map(lambda x: (x[0][0], x[0][1], x[1]))  
  
    result.saveAsTextFile("result")  
  
    sc.stop()  
  
if __name__ == "__main__":  
    input_file = "input.txt"  
    score_statistics(input_file)
```
# è¿è¡Œç¤ºä¾‹

## é¢˜ç›® 1

![[afb89c9935f7db81221306cd4650f6ea.png]]

## é¢˜ç›® 2

### 1.

![[9f156480163f19ce770b60fb91991281.png]]

### 2.

![[af7874a291f2ff8230ff6b26f89c2a9d.png]]

## é¢˜ç›® 3

![[96c890cc19399ebcbf6fc4525d9ad4d5.png]] 

## é¢˜ç›® 4

![[7b460380eb279efe23598abc4b5d49be 1.png]]